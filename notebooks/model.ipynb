{"cells":[{"cell_type":"code","execution_count":null,"metadata":{"cell_id":"22f22e66e9b147e8a002ed4d3ee7eaa9","deepnote_cell_type":"code","deepnote_to_be_reexecuted":false,"execution_millis":5370,"execution_start":1676444273388,"source_hash":"2b01a005","tags":[]},"outputs":[],"source":["import mido\n","import random\n","import os\n","import pandas as pd\n","import numpy as np\n","\n","import smtplib\n","from email.mime.multipart import MIMEMultipart\n","from email.mime.base import MIMEBase\n","from email.mime.text import MIMEText\n","from email.utils import COMMASPACE\n","from email import encoders\n","\n","from sklearn.preprocessing import LabelEncoder\n","from sklearn.model_selection import train_test_split\n","from keras.models import Sequential, load_model\n","from keras import optimizers, regularizers\n","from keras.layers import GRU, LSTM, Dropout, Dense, BatchNormalization\n","from keras.callbacks import EarlyStopping, LearningRateScheduler\n","from keras.optimizers import Adam\n"]},{"cell_type":"code","execution_count":null,"metadata":{},"outputs":[],"source":["MAX_TIME_STEPS = 1000\n","RealMidiFolder = \"../assets/realMusic\"\n","FakeMidiFolder = \"../assets/fakeMusic\"\n","RealCSVFolder = \"../assets/csvs/realCSVs\"\n","FakeCSVFolder = \"../assets/csvs/fakeCSVs\"\n","ModelLocation = \"../models\""]},{"attachments":{},"cell_type":"markdown","metadata":{},"source":["## Generate Random Music"]},{"cell_type":"code","execution_count":null,"metadata":{},"outputs":[],"source":["def generateRandomMidiFiles(numFiles):\n","    # Generate random MIDI events\n","    for x in range(numFiles):\n","        outfile = f\"{FakeMidiFolder}/randomMidi{x}.mid\"\n","        mid = mido.MidiFile()\n","\n","        # Create a new MIDI track\n","        track = mido.MidiTrack()\n","        mid.tracks.append(mido.MidiTrack())\n","        mid.tracks.append(track)\n","\n","        for i in range(MAX_TIME_STEPS):    \n","            # Generate a message based on the type\n","\n","            message = mido.Message('note_on', note=random.randint(0, 127), velocity=random.randint(0, 127), time=random.randint(0, 1200))\n","\n","            # Add the message to the track\n","            track.append(message)\n","\n","        # Save the MIDI file\n","        mid.save(outfile)\n","\n","#For row in realCSVs, add a new random number to each value\n","def addNoiseToCSVs(realCSVsFolder = RealCSVFolder, fakeCSVs = FakeCSVFolder):\n","    for csv in os.listdir(realCSVsFolder):\n","        try:\n","            # Read the CSV file into a dataframe\n","            df = pd.read_csv(f\"{RealCSVFolder}/{csv}\")\n","        except:\n","            os.remove(f\"{RealCSVFolder}/{csv}\")\n","            continue\n","        \n","        # Add random noise to each column\n","        df['track'] = df['track']\n","        df['note'] = df['note'] + np.random.randint(0, 11, len(df))\n","        df['velocity'] = df['velocity']\n","        df['time'] = df['time']\n","\n","        # Write the modified dataframe to a new CSV file\n","        df.to_csv(f'{fakeCSVs}/{csv.split(\".\")[0]}_modified.csv', index=False)"]},{"cell_type":"markdown","metadata":{"cell_id":"64c25c9a88934717a8e289c8d2b2307c","deepnote_cell_type":"text-cell-h2","formattedRanges":[],"is_collapsed":false,"tags":[]},"source":["## MIDI processing functions"]},{"cell_type":"code","execution_count":null,"metadata":{"cell_id":"e98307e68f444785a7cf9d40f8467866","deepnote_cell_type":"code","deepnote_to_be_reexecuted":false,"execution_millis":2,"execution_start":1676444278765,"source_hash":"bb7d34ef","tags":[]},"outputs":[],"source":["def getMidiDF(fileLoc: str):\n","    print(fileLoc)\n","    # Store the data from the MIDI file in a list of dictionaries\n","    mid = mido.MidiFile(fileLoc, clip=True)\n","    midi_data = []\n","    for i, track in enumerate(mid.tracks):\n","        addTime = 0\n","        for msg in track:\n","            if msg.type == \"note_on\":\n","                addTime += msg.time\n","                midi_data.append(\n","                    {\n","                        \"track\": i,\n","                        \"note\": msg.note,\n","                        \"velocity\": msg.velocity,\n","                        \"time\": msg.time,\n","                    }\n","                )\n","\n","    # Convert the list of dictionaries to a Pandas DataFrame\n","    df = pd.DataFrame(midi_data)\n","\n","    # Check if the DataFrame has fewer than MAX_TIME_STEP rows\n","    if df.shape[0] < MAX_TIME_STEPS:\n","        # Calculate the number of rows to pad with zeros\n","        num_rows_to_pad = MAX_TIME_STEPS - df.shape[0]\n","\n","        # Create a new DataFrame with the necessary number of rows and columns\n","        padded_df = pd.DataFrame(\n","            np.zeros((num_rows_to_pad, df.shape[1])), columns=df.columns\n","        )\n","\n","        # Concatenate the original DataFrame and the padded DataFrame\n","        df = pd.concat([df, padded_df])\n","\n","    # Return the DataFrame with exactly MAX_TIME_STEPS rows\n","    return df[:MAX_TIME_STEPS]\n","\n","\n","def saveMidiFromDF(df: pd.DataFrame, midiFileName: str):\n","    mid = mido.MidiFile()\n","    tracks = [mido.MidiTrack() for i in df[\"track\"].unique()]\n","    for track in tracks:\n","        mid.tracks.append(track)\n","\n","    # Iterate through the DataFrame and add the messages to the tracks\n","    for i, row in df.iterrows():\n","        msg = mido.Message(\n","            type=\"note_on\", note=row[\"note\"], velocity=row[\"velocity\"], time=row[\"time\"]\n","        )\n","        tracks[row[\"track\"]].append(msg)\n","\n","    # Save the MIDI file\n","    mid.save(midiFileName)\n","\n","#Load Midi file from CSV\n","def saveMidiFromCSV(csvFile: str, midiFileName: str):\n","    df = pd.read_csv(csvFile)\n","    saveMidiFromDF(df, midiFileName)\n"]},{"cell_type":"markdown","metadata":{"cell_id":"68d151a6283a4b3d83646d72427c15b0","deepnote_cell_type":"text-cell-h2","formattedRanges":[],"is_collapsed":false,"tags":[]},"source":["## MIDI file import/export functions"]},{"cell_type":"code","execution_count":null,"metadata":{"cell_id":"edb3d26528114a64a079888c9424e197","deepnote_cell_type":"code","deepnote_to_be_reexecuted":false,"execution_millis":3,"execution_start":1676444278779,"source_hash":"3c24a72d","tags":[]},"outputs":[],"source":["\n","def createCSVs(listOfDFs, folder):\n","    for i, df in enumerate(listOfDFs):\n","        df[:MAX_TIME_STEPS].to_csv(f\"{folder}/{i}.csv\", index=False)\n","\n","def importMidisAndCreateCSVs(inputMidiFolder: str, outputCSVfolder: str):\n","    trainingDFs = []\n","    # Iterate over all subdirectories within the root folder\n","    for subdir, dirs, files in os.walk(inputMidiFolder):\n","        # Iterate over all files within the subdirectory\n","        for f in files:\n","            filePath = os.path.join(subdir, f)\n","            try:\n","                trainingDFs.append(getMidiDF(filePath))\n","            except:\n","                os.remove(filePath)\n","                continue\n","\n","    createCSVs(trainingDFs, outputCSVfolder)\n","    addNoiseToCSVs()\n","\n","\n","\n","def loadCSVsToNumpy3DArray(folder):\n","    df_list = []\n","    for subdir, dirs, files in os.walk(folder):\n","        # Iterate over all files within the subdirectory\n","        for f in files:\n","            filePath = os.path.join(subdir, f)\n","            try:\n","                df_list.append(pd.read_csv(filePath))\n","            except:\n","                continue\n","            \n","    # Pad the arrays with zeros to make them all have the same number of time steps\n","    paddedDFs = [\n","        np.pad(df.values, ((0, MAX_TIME_STEPS - df.shape[0]), (0, 0)), \"constant\")\n","        for df in df_list\n","    ]\n","\n","    # Stack the arrays along the first axis to create a 3D array\n","    kerasMidiData = np.stack(paddedDFs)\n","    return kerasMidiData\n","\n","def csvToMidi(csvFilePath, midiFilePath):\n","    # Read the CSV file into a pandas dataframe\n","    df = pd.read_csv(csvFilePath)\n","\n","    # Create a new MIDI file with one track\n","    midiFile = mido.MidiFile()\n","    track = mido.MidiTrack()\n","    midiFile.tracks.append(track)\n","\n","    # Set the initial time and velocity values\n","    time = 0\n","    velocity = 64\n","\n","    # Iterate through each row of the CSV file\n","    for index, row in df.iterrows():\n","        # Get the values from the row\n","        trackNumber = row['track']\n","        note = row['note']\n","        velocity = row['velocity']\n","        deltaTime = row['time']\n","\n","        # Create a new message with the values from the row\n","        msg = mido.Message('note_on', note=note, velocity=velocity, time=deltaTime)\n","\n","        # Add the message to the track\n","        track.append(msg)\n","\n","    # Save the MIDI file\n","    midiFile.save(midiFilePath)"]},{"cell_type":"markdown","metadata":{"cell_id":"43129f927f854797b88b78f08dd4c74b","deepnote_cell_type":"text-cell-h2","formattedRanges":[],"is_collapsed":false,"tags":[]},"source":["## Data preparation functions"]},{"cell_type":"code","execution_count":null,"metadata":{"cell_id":"103aa554de324642830c29aa70719b83","deepnote_cell_type":"code","deepnote_to_be_reexecuted":false,"execution_millis":2,"execution_start":1676444278796,"source_hash":"f63c1c50","tags":[]},"outputs":[],"source":["def getNumpy3DArray(listOfTrainingDFs):\n","    # Find the maximum number of time steps\n","\n","    # Pad the arrays with zeros to make them all have the same number of time steps\n","    paddedDFs = [\n","        np.pad(df, [(0, MAX_TIME_STEPS - df.shape[0]), (0, 0)], \"constant\")\n","        for df in listOfTrainingDFs\n","    ]\n","\n","    # Stack the arrays along the first axis to create a 3D array\n","    kerasMidiData = np.stack(paddedDFs)\n","    return kerasMidiData"]},{"cell_type":"markdown","metadata":{"cell_id":"8175a782644f4a9694f78b5527a93296","deepnote_cell_type":"text-cell-h2","formattedRanges":[],"is_collapsed":false,"tags":[]},"source":["## Load and prepare the data"]},{"cell_type":"code","execution_count":null,"metadata":{"cell_id":"4287a91b04c7499c94ffdd07c8d0b5ea","deepnote_cell_type":"code","deepnote_to_be_reexecuted":false,"execution_millis":55195,"execution_start":1676444278800,"source_hash":"3f453d4d","tags":[]},"outputs":[],"source":["print(\"Getting dataframes from Midi Files...\")\n","\n","\n","def createTrainingTestData(realData, fakeData, testSize=0.2, randomState=42):\n","    # Create labels for the real and fake data\n","    realLabels = np.ones((realData.shape[0], 1))\n","    fakeLabels = np.zeros((fakeData.shape[0], 1))\n","\n","    # Combine the real and fake data and labels into a single array\n","    combinedData = np.concatenate((realData, fakeData), axis=0)\n","    combinedLabels = np.concatenate((realLabels, fakeLabels), axis=0)\n","\n","    # Encode the labels using LabelEncoder from scikit-learn\n","    le = LabelEncoder()\n","    encodedLabels = le.fit_transform(combinedLabels.ravel())\n","\n","    # Split the combined data and labels into training and testing sets\n","    X_train, X_test, y_train, y_test = train_test_split(\n","        combinedData, encodedLabels, test_size=testSize, random_state=randomState\n","    )\n","\n","    return X_train, X_test, y_train, y_test\n","\n","def getTrainAndTestFromCSVs(realCSVfolder=RealCSVFolder, fakeCSVfolder=FakeCSVFolder):\n","    realMusicFromCSVs = loadCSVsToNumpy3DArray(realCSVfolder)\n","    fakeMusicFromCSVs = loadCSVsToNumpy3DArray(fakeCSVfolder)\n","    X_train, X_test, y_train, y_test = createTrainingTestData(\n","        realMusicFromCSVs, fakeMusicFromCSVs\n","    )\n","    return X_train, X_test, y_train, y_test\n","\n","\n","def getTrainAndTestFromMidiFolders(realMidiFolder = RealMidiFolder, realCSVFolder = RealCSVFolder, fakeMidiFolder = FakeMidiFolder, fakeCSVFolder = FakeCSVFolder):\n","    importMidisAndCreateCSVs(realMidiFolder, realCSVFolder)\n","    importMidisAndCreateCSVs(fakeMidiFolder, fakeCSVFolder)\n","    X_train, X_test, y_train, y_test = getTrainAndTestFromCSVs()\n","    return X_train, X_test, y_train, y_test"]},{"cell_type":"code","execution_count":null,"metadata":{},"outputs":[],"source":["print(\"Importing data from Midis\")\n","importMidisAndCreateCSVs(\"../assets/realMusic\", \"../assets/csvs/realCSVs\")\n","importMidisAndCreateCSVs(\"../assets/fakeMusic\", \"../assets/csvs/fakeCSVs\")\n","print(\"Adding noise from real CSVs to add to fake CSVs\")\n","addNoiseToCSVs()"]},{"cell_type":"code","execution_count":null,"metadata":{},"outputs":[],"source":["X_train, X_test, y_train, y_test = getTrainAndTestFromCSVs()"]},{"cell_type":"markdown","metadata":{"cell_id":"e4c6167c32db431a8683e85573e4ca6f","deepnote_cell_type":"text-cell-h2","formattedRanges":[],"is_collapsed":false,"tags":[]},"source":["## Model Training and Saving"]},{"cell_type":"code","execution_count":null,"metadata":{"cell_id":"f0292468090b4553bb89666c50959ec2","deepnote_cell_type":"code","deepnote_to_be_reexecuted":true,"execution_millis":2,"execution_start":1676443560600,"source_hash":"c9f2a098","tags":[]},"outputs":[],"source":["def fitModel(X_train, X_test, y_train, y_test): \n","    # Define the model architecture\n","    model = Sequential()\n","    model.add(LSTM(units=256, input_shape=X_train.shape[1:], return_sequences=True))\n","    model.add(Dropout(0.2))\n","    model.add(LSTM(units=64))\n","    model.add(Dense(units=64, activation=\"relu\"))\n","    model.add(Dropout(0.2))\n","    model.add(Dense(units=1, activation=\"sigmoid\"))\n","\n","    # Define the optimizer\n","    opt = optimizers.SGD(learning_rate=0.05)\n","\n","    # Define callbacks\n","    early_stop = EarlyStopping(monitor='val_loss', patience=5)\n","    def scheduler(epoch, lr):\n","        if epoch < 10:\n","            return lr\n","\n","        else:\n","            return lr * 0.1\n","    lr_scheduler = LearningRateScheduler(scheduler)\n","\n","    # Compile and fit the model\n","    model.compile(loss=\"binary_crossentropy\", optimizer=opt, metrics=[\"accuracy\"])\n","    history = model.fit(X_train, y_train, epochs=10, batch_size=32, validation_split=0.2, callbacks=[early_stop, lr_scheduler])\n","\n","    # Evaluate the model on the testing data\n","    loss, accuracy = model.evaluate(X_test, y_test)\n","    print(\"Test loss:\", loss)\n","    print(\"Test accuracy:\", accuracy)\n","\n","    # Save the trained model to a file\n","    model.save(\"model.h5\")"]},{"cell_type":"code","execution_count":111,"metadata":{},"outputs":[{"name":"stdout","output_type":"stream","text":["28/35 [=======================>......] - ETA: 8s - loss: 0.5996 - accuracy: 0.5848"]},{"ename":"KeyboardInterrupt","evalue":"","output_type":"error","traceback":["\u001b[0;31m---------------------------------------------------------------------------\u001b[0m","\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)","\u001b[0;32m/var/folders/fw/30zxms3d5_z_f6hjw9frq67r0000gn/T/ipykernel_18773/3872358485.py\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0mfitModel\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mX_train\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mX_test\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my_train\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my_test\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m","\u001b[0;32m/var/folders/fw/30zxms3d5_z_f6hjw9frq67r0000gn/T/ipykernel_18773/2454551872.py\u001b[0m in \u001b[0;36mfitModel\u001b[0;34m(X_train, X_test, y_train, y_test)\u001b[0m\n\u001b[1;32m     24\u001b[0m     \u001b[0;31m# Compile and fit the model\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     25\u001b[0m     \u001b[0mmodel\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcompile\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mloss\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m\"binary_crossentropy\"\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0moptimizer\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mopt\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmetrics\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m\"accuracy\"\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 26\u001b[0;31m     \u001b[0mhistory\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mmodel\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfit\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mX_train\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my_train\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mepochs\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m10\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mbatch_size\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m32\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mvalidation_split\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m0.2\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcallbacks\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mearly_stop\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mlr_scheduler\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     27\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     28\u001b[0m     \u001b[0;31m# Evaluate the model on the testing data\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m/Library/Frameworks/Python.framework/Versions/3.10/lib/python3.10/site-packages/keras/utils/traceback_utils.py\u001b[0m in \u001b[0;36merror_handler\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m     63\u001b[0m         \u001b[0mfiltered_tb\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     64\u001b[0m         \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 65\u001b[0;31m             \u001b[0;32mreturn\u001b[0m \u001b[0mfn\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     66\u001b[0m         \u001b[0;32mexcept\u001b[0m \u001b[0mException\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0me\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     67\u001b[0m             \u001b[0mfiltered_tb\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0m_process_traceback_frames\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0me\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m__traceback__\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m/Library/Frameworks/Python.framework/Versions/3.10/lib/python3.10/site-packages/keras/engine/training.py\u001b[0m in \u001b[0;36mfit\u001b[0;34m(self, x, y, batch_size, epochs, verbose, callbacks, validation_split, validation_data, shuffle, class_weight, sample_weight, initial_epoch, steps_per_epoch, validation_steps, validation_batch_size, validation_freq, max_queue_size, workers, use_multiprocessing)\u001b[0m\n\u001b[1;32m   1648\u001b[0m                         ):\n\u001b[1;32m   1649\u001b[0m                             \u001b[0mcallbacks\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mon_train_batch_begin\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mstep\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1650\u001b[0;31m                             \u001b[0mtmp_logs\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtrain_function\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0miterator\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1651\u001b[0m                             \u001b[0;32mif\u001b[0m \u001b[0mdata_handler\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mshould_sync\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1652\u001b[0m                                 \u001b[0mcontext\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0masync_wait\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m/Library/Frameworks/Python.framework/Versions/3.10/lib/python3.10/site-packages/tensorflow/python/util/traceback_utils.py\u001b[0m in \u001b[0;36merror_handler\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m    148\u001b[0m     \u001b[0mfiltered_tb\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    149\u001b[0m     \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 150\u001b[0;31m       \u001b[0;32mreturn\u001b[0m \u001b[0mfn\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    151\u001b[0m     \u001b[0;32mexcept\u001b[0m \u001b[0mException\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0me\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    152\u001b[0m       \u001b[0mfiltered_tb\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0m_process_traceback_frames\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0me\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m__traceback__\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m/Library/Frameworks/Python.framework/Versions/3.10/lib/python3.10/site-packages/tensorflow/python/eager/polymorphic_function/polymorphic_function.py\u001b[0m in \u001b[0;36m__call__\u001b[0;34m(self, *args, **kwds)\u001b[0m\n\u001b[1;32m    878\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    879\u001b[0m       \u001b[0;32mwith\u001b[0m \u001b[0mOptionalXlaContext\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_jit_compile\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 880\u001b[0;31m         \u001b[0mresult\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_call\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwds\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    881\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    882\u001b[0m       \u001b[0mnew_tracing_count\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mexperimental_get_tracing_count\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m/Library/Frameworks/Python.framework/Versions/3.10/lib/python3.10/site-packages/tensorflow/python/eager/polymorphic_function/polymorphic_function.py\u001b[0m in \u001b[0;36m_call\u001b[0;34m(self, *args, **kwds)\u001b[0m\n\u001b[1;32m    910\u001b[0m       \u001b[0;31m# In this case we have created variables on the first call, so we run the\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    911\u001b[0m       \u001b[0;31m# defunned version which is guaranteed to never create variables.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 912\u001b[0;31m       \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_no_variable_creation_fn\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwds\u001b[0m\u001b[0;34m)\u001b[0m  \u001b[0;31m# pylint: disable=not-callable\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    913\u001b[0m     \u001b[0;32melif\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_variable_creation_fn\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    914\u001b[0m       \u001b[0;31m# Release the lock early so that multiple threads can perform the call\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m/Library/Frameworks/Python.framework/Versions/3.10/lib/python3.10/site-packages/tensorflow/python/eager/polymorphic_function/tracing_compiler.py\u001b[0m in \u001b[0;36m__call__\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m    132\u001b[0m       (concrete_function,\n\u001b[1;32m    133\u001b[0m        filtered_flat_args) = self._maybe_define_function(args, kwargs)\n\u001b[0;32m--> 134\u001b[0;31m     return concrete_function._call_flat(\n\u001b[0m\u001b[1;32m    135\u001b[0m         filtered_flat_args, captured_inputs=concrete_function.captured_inputs)  # pylint: disable=protected-access\n\u001b[1;32m    136\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m/Library/Frameworks/Python.framework/Versions/3.10/lib/python3.10/site-packages/tensorflow/python/eager/polymorphic_function/monomorphic_function.py\u001b[0m in \u001b[0;36m_call_flat\u001b[0;34m(self, args, captured_inputs, cancellation_manager)\u001b[0m\n\u001b[1;32m   1743\u001b[0m         and executing_eagerly):\n\u001b[1;32m   1744\u001b[0m       \u001b[0;31m# No tape is watching; skip to running the function.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1745\u001b[0;31m       return self._build_call_outputs(self._inference_function.call(\n\u001b[0m\u001b[1;32m   1746\u001b[0m           ctx, args, cancellation_manager=cancellation_manager))\n\u001b[1;32m   1747\u001b[0m     forward_backward = self._select_forward_and_backward_functions(\n","\u001b[0;32m/Library/Frameworks/Python.framework/Versions/3.10/lib/python3.10/site-packages/tensorflow/python/eager/polymorphic_function/monomorphic_function.py\u001b[0m in \u001b[0;36mcall\u001b[0;34m(self, ctx, args, cancellation_manager)\u001b[0m\n\u001b[1;32m    376\u001b[0m       \u001b[0;32mwith\u001b[0m \u001b[0m_InterpolateFunctionError\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    377\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mcancellation_manager\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 378\u001b[0;31m           outputs = execute.execute(\n\u001b[0m\u001b[1;32m    379\u001b[0m               \u001b[0mstr\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msignature\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mname\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    380\u001b[0m               \u001b[0mnum_outputs\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_num_outputs\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m/Library/Frameworks/Python.framework/Versions/3.10/lib/python3.10/site-packages/tensorflow/python/eager/execute.py\u001b[0m in \u001b[0;36mquick_execute\u001b[0;34m(op_name, num_outputs, inputs, attrs, ctx, name)\u001b[0m\n\u001b[1;32m     50\u001b[0m   \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     51\u001b[0m     \u001b[0mctx\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mensure_initialized\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 52\u001b[0;31m     tensors = pywrap_tfe.TFE_Py_Execute(ctx._handle, device_name, op_name,\n\u001b[0m\u001b[1;32m     53\u001b[0m                                         inputs, attrs, num_outputs)\n\u001b[1;32m     54\u001b[0m   \u001b[0;32mexcept\u001b[0m \u001b[0mcore\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_NotOkStatusException\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0me\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;31mKeyboardInterrupt\u001b[0m: "]}],"source":["fitModel(X_train, X_test, y_train, y_test)"]},{"cell_type":"code","execution_count":null,"metadata":{},"outputs":[],"source":["def sendEmail(accuracy, loss):\n","    # Define the email content\n","    msg = MIMEMultipart()\n","    msg['Subject'] = f'Trained model - Accuracy: {accuracy:.2f} - Loss: {loss:.2f}'\n","    msg['From'] = 'dpshadey22@gmail.com'\n","    msg['To'] = 'dpshadey22@gmail.com'\n","    msg.attach(MIMEText('Please find attached the trained model.'))\n","\n","    # Add the model file as an attachment\n","    with open('model.h5', 'rb') as f:\n","        part = MIMEBase('application', 'octet-stream')\n","        part.set_payload(f.read())\n","        encoders.encode_base64(part)\n","        part.add_header('Content-Disposition', 'attachment', filename='model.h5')\n","        msg.attach(part)\n","\n","    # Send the email\n","    server = smtplib.SMTP(\"smtp.gmail.com\", 587)\n","    server.starttls()\n","    server.login(\"dpshadey22@gmail.com\", \"eghrbpkjmywgkrsv\")\n","\n","    server.send_message(msg)\n","    server.quit()\n","\n","    print(\"Email sent successfully.\")\n"]},{"cell_type":"markdown","metadata":{"cell_id":"369a0a3e15e84b73b1a062f64d131bb8","deepnote_cell_type":"text-cell-h2","formattedRanges":[],"is_collapsed":false,"tags":[]},"source":["## Model Prediction"]},{"cell_type":"code","execution_count":null,"metadata":{},"outputs":[],"source":["\n","def predictNewMidi(filePath, modelFile):\n","    model = load_model(modelFile)\n","\n","    # Load the MIDI file into a Pandas DataFrame\n","    midi_df = getMidiDF(filePath)\n","\n","    # Add a new dimension at the beginning to represent the batch size\n","    midi_array = np.expand_dims(midi_df.values, axis=0)\n","\n","    # Pad the array with zeros to match the expected shape of (x, MAX_TIME_STEPS, 4)\n","\n","    if midi_array.shape[1] < MAX_TIME_STEPS:\n","        padding = ((0, 0), (0, MAX_TIME_STEPS - midi_array.shape[1]), (0, 0))\n","        midi_array = np.pad(midi_array, padding, mode=\"constant\")\n","\n","    # Use the model to predict the output\n","    predictions = model.predict(midi_array)\n","\n","    return predictions"]},{"cell_type":"code","execution_count":null,"metadata":{"cell_id":"c92d50c5c9ef4911bcddd4f7cc4fc1de","deepnote_cell_type":"code","deepnote_to_be_reexecuted":true,"execution_millis":0,"execution_start":1676443560600,"source_hash":"89e2f2df","tags":[]},"outputs":[],"source":["print(predictNewMidi(\"./720_modified.mid\", f\"{ModelLocation}/model.h5\"))"]}],"metadata":{"deepnote":{},"deepnote_execution_queue":[],"deepnote_notebook_id":"1e169e7e8ab7448cbd84d18eb98a3be0","kernelspec":{"display_name":"Python 3","language":"python","name":"python3"},"language_info":{"codemirror_mode":{"name":"ipython","version":3},"file_extension":".py","mimetype":"text/x-python","name":"python","nbconvert_exporter":"python","pygments_lexer":"ipython3","version":"3.10.0"},"orig_nbformat":2,"vscode":{"interpreter":{"hash":"aee8b7b246df8f9039afb4144a1f6fd8d2ca17a180786b69acc140d282b71a49"}}},"nbformat":4,"nbformat_minor":0}
